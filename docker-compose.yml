version: '3.5'

# Note, don't use port 8080 because google oauth uses that

services:
  agent: # The new agent, no actual llm required
    build: ./agent
    container_name: agent
    ports:
      - "10000:10000"
      - "8000:8000"
    environment:
      - MEMORY
      - OPENAI_API_KEY
      - OPENAI_API_TYPE
      - OPENAI_API_BASE
      - OPENAI_API_VERSION
      - OPENAI_DEPLOYMENT_NAME
      - OPENAI_MODEL
      - GOOGLE_API_KEY
      - GOOGLE_CSE_ID
      - WOLFRAM_ALPHA_APPID
      - APIFY_API_TOKEN

  api:
    image: quay.io/go-skynet/local-ai:latest
    container_name: api
    ports:
      - 8765:8765
    env_file:
      - LocalAI.env
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/api:/models:cached
    command: ["/usr/bin/local-ai" ]

  webui: # The (currently web) interface for the assistant
    build: ./webui
    container_name: webui
    ports:
      - "3000:3000"
    environment:
      MILVUS_HOST: standalone
      DALAI_HOST: dalai
      GPT4ALL_HOST: gpt4all

  clickhouse:
    image: clickhouse/clickhouse-server:22.9-alpine
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
      - CLICKHOUSE_TCP_PORT=9000
      - CLICKHOUSE_HTTP_PORT=8123
    ports:
      - '8123:8123'
      - '9000:9000'
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/clickhouse/data:/bitnami/clickhouse
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/clickhouse/backups:/backups
      # - ./clickhouse/backup_disk.xml:/etc/clickhouse-server/config.d/backup_disk.xml
      # - ./clickhouse/chroma_users.xml:/etc/clickhouse-server/users.d/chroma.xml

  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: chroma
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/chroma:/index_data
    command: uvicorn chromadb.app:app --reload --workers 1 --host 0.0.0.0 --port 6000 --log-config log_config.yml
    environment:
      - CHROMA_DB_IMPL=clickhouse
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=8123
    ports:
      - 6000:6000
    depends_on:
      - clickhouse

# https://tts.readthedocs.io/en/latest/
  tts:
    container_name: tts
    # image: ghcr.io/coqui-ai/tts-cpu:latest
    image: synesthesiam/mozillatts:en
    # entrypoint: python3 TTS/server/server.py --model_name tts_models/en/vctk/vits
    ports:
      - "5002:5002"

  # motorhead: # Memory
  #   container_name: motorhead
  #   image: ghcr.io/getmetal/motorhead:latest
  #   ports:
  #     - "8001:8001"
  #   environment:
  #     - PORT=8001
  #     - REDIS_URL=redis://redis:6379
  #     - MOTORHEAD_LONG_TERM_MEMORY=True
  #     - OPENAI_API_KEY
  #     - OPENAI_API_TYPE
  #     - OPENAI_API_BASE
  #     - OPENAI_API_VERSION
  #     - OPENAI_DEPLOYMENT_NAME
  #   depends_on:
  #     - "redis"

  # redis:
  #   container_name: redis
  #   image: redis/redis-stack:latest
  #   restart: always
  #   ports:
  #     - '6379:6379'
  #   volumes: 
  #     - redis:/data

# volumes:
#   redis:
#     driver: local
